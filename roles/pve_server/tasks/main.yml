---
- name: determine if enterprise pve subscription exists
  stat: path=/etc/apt/apt.conf.d/86pve-nags
  register: pve_enterprise_nag_buster

- name: determine if pve community repository present
  stat: path=/etc/apt/sources.list.d/pve-community.list
  register: pve_community_repository

- name: determine if pve enterprise repository present
  stat: path=/etc/apt/sources.list.d/pve-enterprise.list
  register: pve_enterprise_repository

- name: determine if vendor-reset dkms module already exists
  stat: path=/var/lib/dkms/vendor-reset/0.1.1
  register: vendor_reset_dkms

- name: ensure old pve community repository removed
  command: mv /etc/apt/sources.list.d/pve-community.list /etc/apt/sources.list.d/pve-community.list.disabled
  become: true
  when: pve_community_repository.stat.exists

- name: ensure original pve enterprise repository removed
  command: mv /etc/apt/sources.list.d/pve-enterprise.list /etc/apt/sources.list.d/pve-enterprise.list.disabled
  become: true
  when: pve_enterprise_repository.stat.exists

- name: Ensures ~ansible/Downloads dir exists
  file:
    path: "/home/{{ ansible_env.USER }}/Downloads"
    state: directory
  when: in_bootstrap is not defined

- name: copy pve-nag-buster/install.sh to pve
  copy:
    src: /home/tconnors/code/proxmox/pve-nag-buster/install.sh
    dest: "/home/{{ ansible_env.USER }}/Downloads/pve-nag-buster-install.sh"
    mode: 0755
  register: pve_nag_buster_changed
  when: in_bootstrap is not defined

- name: install the pve nag buster
  command: /home/{{ ansible_env.USER }}/Downloads/pve-nag-buster-install.sh --offline
  become: true
  when: in_bootstrap is not defined and ( not pve_enterprise_nag_buster.stat.exists or pve_nag_buster_changed.changed )
  register: pve_nag_installed

- name: Install pve prereq packages
  apt:
    name: ['dkms', 'pve-headers', 'ifupdown2']
    autoremove: no
    state: present
    install_recommends: no
  become: true
  when: in_bootstrap is not defined

- name: Ensures ~ansible/Downloads/vendor-reset-225a49a dir exists
  file:
    path: "/home/{{ ansible_env.USER }}/Downloads/vendor-reset-225a49a"
    state: directory
  when: in_bootstrap is not defined

- name: copy AMD graphics vendor-reset to pve
  unarchive:
    src: /home/tconnors/code/vendor-reset-225a49a.tar
    dest: "/home/{{ ansible_env.USER }}/Downloads/vendor-reset-225a49a"
    extra_opts:
    - --transform
    - s/^vendor-reset//
  register: vendor_reset_changed
  # want to rethink this, but in check_mode, we can't hope to unpack
  # the archive when the user doesn't yet exist
  when: not ansible_check_mode and in_bootstrap is not defined and not vendor_reset_dkms.stat.exists

- name: install AMD graphics vendor-reset to pve
#  command: bash -c 'cd Downloads/vendor-reset-225a49a ; dkms install .'
  command: dkms install .
  args:
    chdir: /home/{{ ansible_env.USER }}/Downloads/vendor-reset-225a49a
  become: true
  # want to rethink this, but in check_mode, we can't hope to unpack
  # the archive when the archive isn't yet unpacked
  when: not ansible_check_mode and in_bootstrap is not defined and ( not vendor_reset_dkms.stat.exists or vendor_reset_changed.changed )

- name: remove prohibited packages
  apt:
    name: "{{ item }}"
    state: absent
  become: true
  with_items:
    - 'os-prober'
    - 'linux-headers-*'
    - 'linux-image-*'
    # https://github.com/ansible/ansible/issues/62262 - can't do all
    # these at once on the one invocation, because throws extraneous
    # errors when the package was never installed
  ignore_errors: true

- name: Install virtual host tools
  apt:
    # https://pve.proxmox.com/wiki/Install_Proxmox_VE_on_Debian_Jessie
    name: ['proxmox-ve', 'ssh', 'postfix', 'ksm-control-daemon', 'open-iscsi', 'systemd-sysv', 'munin-libvirt-plugins', 'targetcli-fb', 'powertop', 'libguestfs-tools', 'hwloc', 'numad'] # 'virt-goodies',
#, 'swapspace']
#    FIXME: run tuned-adm profile powersave or perhaps virtual-host # https://www.reddit.com/r/Proxmox/comments/uc53m7/4port_j4125_pc_how_to_run_proxmox_with_lowpower/
    update_cache: yes
    cache_valid_time: 3600
    autoremove: no
    state: present
  become: true

- name: mount media
  mount:
    path: /media
    src: fs:/home/tconnors/movies/media
    fstype: nfs4
    opts: defaults,_netdev,x-systemd.automount
    state: mounted
  become: true

- name: mount media transcodes
  mount:
    path: /transcodes
    src: fs:/home/tconnors/movies/media_transcodes
    fstype: nfs4
    opts: defaults,_netdev,x-systemd.automount
    state: mounted
  become: true

- name: ensure SMR drives have a longer timeout
  copy:
     content: "ACTION==\"add\", SUBSYSTEM==\"block\",  ENV{ID_MODEL}==\"ST8000AS0002*\", RUN+=\"/bin/sh -c 'echo 60 > /sys/block/%k/device/timeout'\"\n"
     # find string with `udevadm test /sys/class/block/sdf`
     # also tells you whether it appended RUN appropriately
     dest: /etc/udev/rules.d/90-SMR-drive-timeout.rules
  become: true

- name: install suspend-all
  copy:
    src: pve_server/{{ item }}
    dest: /usr/local/bin/{{ item }}
    owner: root
    group: root
    mode: 0755
  become: true
  with_items:
    - suspend-all

  # FIXME: there are no non-zfs partitions on pve where there's enough space for swapspace to operate
#- name: Ensures /var/lib/swapspace 0700
#  file:
#    path="/var/lib/swapspace"
#    state=directory
#    mode=0700
#  become: true

# these smart_ links are in addition to those handled by munin_suggest_plugin.yml, which appears to ignore devices that are sent through to VMs (where we still have to run the smart queries from)
- name: ensure all munin smart links are in place
  file:
    src: /usr/share/munin/plugins/smart_
    dest: "/etc/munin/plugins/smart_sd{{ item }}"
    state: link
  become: true
  with_items: { a, b, c, d, e, f, g, h, i, j, k, l, m, n }
  when: in_bootstrap is not defined

- name: disable pve-ha-lrm/pve-ha-crm on a non HA setup, to alleviate constant disk writes by pmxcfs to SSD
  # https://forum.proxmox.com/threads/pmxcfs-writing-to-disk-all-the-time.35828/ https://www.reddit.com/r/Proxmox/comments/i8e5fi/excessive_nvme_wear_out/g193xr2/
  service:
    name: "{{ item }}"
    enabled: "{{ ( host_is_in_pve_cluster is defined and host_is_in_pve_cluster ) | ternary('yes', 'no') }}"
    state: "{{ ( host_is_in_pve_cluster is defined and host_is_in_pve_cluster ) | ternary('started', 'stopped') }}"
  become: true
  with_items:
    - pve-ha-lrm
    - pve-ha-crm

- name: reduce frequent writes by pvesr.timer
  # https://forum.proxmox.com/threads/replication-runner-syslog.35600/
  copy:
    content: "[Unit]\nDescription=Proxmox VE replication runner\n\n[Timer]\nAccuracySec=1\nRemainAfterElapse=no\n\n[Timer]\nOnCalendar=*:0/15\n\n[Install]\nWantedBy=timers.target\n"
    dest: /etc/systemd/system/pvesr.timer
  become: true

  # FIXME: consider also reducing rrd writes: https://forum.proxmox.com/threads/reducing-rrdcached-writes.64473/
# (but primarily, suspect most writes are coming from rrd in fs)


#FIXME: all these (and essentials, and spectre) grub commandline mungings should just be additions and deletions to file from /etc/default/grub.d/
# https://pve.proxmox.com/wiki/Pci_passthrough
- name: "Search for intel iommu grub config"
  become: yes
  register: intel_iommu_grub_cmdline_exists
  check_mode: yes # cause this to become just a test.  If there's already
                  # iommu settings, then this will think line is
                  # being replaced, and changed will become true (but we
                  # force it to false to not output a line saying
                  # "changed"), and msg will become "line added", else
                  # changed stays false, and msg does not contain "line
                  # added"
  lineinfile:
    dest: /etc/default/grub
    line: grub cmdline already has iommu mitigations disabled
    regexp: "^GRUB_CMDLINE_LINUX_DEFAULT=.*intel_iommu=on"
    state: present
  changed_when: false

# https://pve.proxmox.com/wiki/Pci_passthrough
- name: "Search for amd iommu grub config"
  become: yes
  register: amd_iommu_grub_cmdline_exists
  check_mode: yes # cause this to become just a test.  If there's already
                  # iommu settings, then this will think line is
                  # being replaced, and changed will become true (but we
                  # force it to false to not output a line saying
                  # "changed"), and msg will become "line added", else
                  # changed stays false, and msg does not contain "line
                  # added"
  lineinfile:
    dest: /etc/default/grub
    line: grub cmdline already has iommu mitigations disabled
    regexp: "^GRUB_CMDLINE_LINUX_DEFAULT=.*amd_iommu=on"
    state: present
  changed_when: false


  # test devices you want to pass through belong in separate IOMMUs:
#https://www.reddit.com/r/SolusProject/comments/955osy/vfio_passthrough_quick_reference/
##!/bin/bash
#shopt -s nullglob
#for d in /sys/kernel/iommu_groups/*/devices/*; do
#    n=${d#*/iommu_groups/*}; n=${n%%/*}
#    printf 'IOMMU Group %s ' "$n"
#    lspci -nns "${d##*/}"
#done;

- name: "Append intel_iommu=on grub config"
  when: (intel_iommu_grub_cmdline_exists.msg == "line added") and (host_is_intel is defined)
  lineinfile:
    dest: /etc/default/grub
    backrefs: yes
    regexp: '^GRUB_CMDLINE_LINUX_DEFAULT="(.*)"'
    line: 'GRUB_CMDLINE_LINUX_DEFAULT="\1 intel_iommu=on iommu=pt pcie_acs_override=downstream,multifunction"'
    state: present
  become: true
  notify: "Regenerate pve grub config"

- name: "Append amd_iommu=on grub config"
  when: (amd_iommu_grub_cmdline_exists.msg == "line added") and (host_is_amd is defined)
  lineinfile:
    dest: /etc/default/grub
    backrefs: yes
    regexp: '^GRUB_CMDLINE_LINUX_DEFAULT="(.*)"'
    line: 'GRUB_CMDLINE_LINUX_DEFAULT="\1 amd_iommu=on iommu=pt pcie_acs_override=downstream,multifunction"'
    state: present
  become: true
  notify: "Regenerate pve grub config"

# - name: "host modules blacklist (radeon, snd_hda_intel, amdgpu, usb3)"
#   copy:
#     dest: /etc/modprobe.d/pve-custom-blacklist.conf
#     content: "# ansible controlled for RX550 by pve_server/main.yml\nblacklist radeon\nblacklist amdgpu\nblacklist snd_hda_intel\nblacklist xhci_hcd\nblacklist xhci_pci\n"
#   become: true
#   notify: "Update initramfs config"

- name: "Search for modprobe blacklist"
  become: yes
  register: modprobe_blacklist_grub_cmdline_exists
  check_mode: yes # cause this to become just a test.  If there's already
                  # blacklist settings, then this will think line is
                  # being replaced, and changed will become true (but we
                  # force it to false to not output a line saying
                  # "changed"), and msg will become "line added", else
                  # changed stays false, and msg does not contain "line
                  # added"
  lineinfile:
    dest: /etc/default/grub
    line: grub cmdline already has modprobe blacklist applied
    regexp: "^GRUB_CMDLINE_LINUX_DEFAULT=.*modprobe.blacklist=.*radeon"
    state: present
  changed_when: false

- name: "Append modprobe.blacklist=... grub config"
  when: modprobe_blacklist_grub_cmdline_exists.msg == "line added"
  lineinfile:
    dest: /etc/default/grub
    backrefs: yes
    regexp: '^GRUB_CMDLINE_LINUX_DEFAULT="(.*)"'
    line: 'GRUB_CMDLINE_LINUX_DEFAULT="\1 modprobe.blacklist=radeon,amdgpu,snd_hda_intel,xhci_hcd,xhci_pci"'
    state: present
  become: true
  notify: "Regenerate pve grub config"

- name: "Search for grub failsafe cmdline"
  become: yes
  register: failsafe_grub_cmdline_exists
  check_mode: yes # cause this to become just a test.  If there's already
                  # blacklist settings, then this will think line is
                  # being replaced, and changed will become true (but we
                  # force it to false to not output a line saying
                  # "changed"), and msg will become "line added", else
                  # changed stays false, and msg does not contain "line
                  # added"
  lineinfile:
    dest: /etc/default/grub
    line: grub cmdline already has failsafe grub cmdline applied
    regexp: "^GRUB_CMDLINE_LINUX=.*modprobe.blacklist=vfio_pci"
    state: present
  changed_when: false

- name: "Append modprobe.blacklist=vfio_pci grub config"
  when: failsafe_grub_cmdline_exists.msg == "line added"
  lineinfile:
    dest: /etc/default/grub
    backrefs: yes
    regexp: '^GRUB_CMDLINE_LINUX="(.*)"'
    line: 'GRUB_CMDLINE_LINUX="\1 modprobe.blacklist=vfio_pci"'
    state: present
  become: true
  notify: "Regenerate pve grub config"

- name: "vfio module parameters"
  copy:
    dest: /etc/modprobe.d/vfio-custom.conf
    # locations obtained with lspci -nvvv
    content: "# ansible controlled to passthrough amdgpu and usb card, by pve_server/main.yml\noptions vfio-pci {{ vfio_ids }}\n"
  become: true
  notify: "Update initramfs config"
  when: vfio_ids is defined 

- name: "Ensure vfio, vendor-reset in /etc/modules"
  lineinfile:
    dest: /etc/modules
    line: "{{ item }}"
    state: present
  become: true
  notify: "Update initramfs config"
  with_items:
    - "# ansible controlled for GPU passthrough and reset by pve_server/main.yml"
    - vfio
    - vfio_iommu_type1
    - vfio_pci
    - vfio_virqfd
    - vendor-reset
    - "# following modules are blacklisted on the kernel commandline to stop from autoloading, but now that vfio is loaded reserving the appropriate devices, we are free to load them again (nope, have to probe them manually)"
    - "#xhci_pci"
    - "#xhci_hcd"

# persistent network names (lan0): https://wiki.debian.org/NetworkInterfaceNames
- name: install systemd network persistent net link
  template:
    src: systemd-network-persistent-net-link.j2
    dest: /etc/systemd/network/10-persistent-net.link
  become: true

- name: install network interfaces
  template:
    src: network-interfaces.j2
    dest: /etc/network/interfaces
  become: true

#FIXME: keep monitoring lifetime left, and if drops below 0 (or Percent_Lifetime_Remain raw value goes above 100 on its way to 255, which then makes lifetime writes somewhere around 264TB, which is much closer to TBW), then it's just a SMART bug and we can back out this timeout back to default 5.  Also, if doesn't drop its rate, might as well back it out too and find some other source of write amplification in the fs VM # https://www.reddit.com/r/zfs/comments/cott44/how_can_i_check_to_make_sure_i_dont_have_a_write/ewqjld0/
- name: "zfs module parameters"
  copy:
    dest: /etc/modprobe.d/zfs-custom.conf
    content: "# ansible controlled to ensure SSD doesn't have too many writes, by pve_server/main.yml\noptions zfs zfs_txg_timeout=15\n"
  become: true
  notify: "Update initramfs config"

# if need to regenerate pve grub config because of new disks,
# procedure is here: https://pve.proxmox.com/wiki/Host_Bootloader

- name: install ssh socket directory
  file:
    path: "/root/.ssh/cm_master"
    state: directory
  become: true

- name: install ssh config
  lineinfile:
    dest: /root/.ssh/config
    line: "{{ item }}"
  with_items:
    - "ControlMaster auto"
    - "ControlPath ~/.ssh/cm_master/%r@%h:%p"
    - "ControlPersist yes"
  become: true

- name: Setup pve users
  copy:
     content: "user:root@pam:1:0:::tim.w.connors@gmail.com:::\n{{ pve_users | join('\n') }}\n"
     dest: /etc/pve/user.cfg
  become: true

- name: "Install root crontab"
  copy:
    dest: /var/spool/cron/crontabs/root
    content: "@reboot echo schedutil | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n"
#    content: "@reboot echo ondemand | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n"
#    content: "@reboot echo powersave | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n"
#    content: "\n"
    mode: 0600
  become: true
  notify: "reload cron"

- name: "Install guest snippets directory"
  file:
    path: "/var/lib/vz/snippets/"
    state: directory
  become: true

- name: "Install guest snippets"
  copy:
    dest: /var/lib/vz/snippets/guest-hookscript.pl
    src: guest-hookscript.pl
    mode: 0755
  become: true


- name: "search for LVM blacklist"
  register: lvm_conf_ansible_marker_exists
  check_mode: yes # cause this to become just a test.  If there's already
                  # an ANSIBLE marker, then this will think line is
                  # being replaced, and changed will become true (but we
                  # force it to false to not output a line saying
                  # "changed"), and msg will become "line added", else
                  # changed stays false, and msg does not contain "line
                  # added" (it contains "line replaced")
  lineinfile:
    dest: /etc/lvm/lvm.conf
    line: lvm.conf already has our rules present
    regexp: 'ANSIBLE_RULES_AFTER'
    state: present
  changed_when: false

- name: debug lvm_conf_ansible_marker_exists
  debug:
    msg: "lvm_conf_ansible_marker_exists = {{ lvm_conf_ansible_marker_exists.msg }}"

- name: "append ansible marker to lvm conf"
  when: (lvm_conf_ansible_marker_exists.msg == "line added")
  lineinfile:
    dest: /etc/lvm/lvm.conf
    backrefs: yes
    regexp: '^(\s*global_filter=.*)"\]'
    line: '\1", "r|ANSIBLE_RULES_AFTER|"]'
    state: present
  become: true

  # https://forum.proxmox.com/threads/disk-prevent-from-spinning-down-because-of-pvestatd.53237/
- name: disks presented through to other VMs blacklisted from local lvm
  lineinfile:
    dest: /etc/lvm/lvm.conf
    backrefs: yes
    regexp: '^(.*global_filter=.*, "r\|ANSIBLE_RULES_AFTER\|").*\]'
    line: '\1, "r|/dev/disk/by-id/scsi-35000.*|"]'
    state: present
  become: true

- name: turn off softdog watchdog reboot
  copy:
    content: "# https://forum.proxmox.com/threads/how-to-disable-fencing-for-debugging.59625/\noptions softdog soft_noboot=1\n"
    dest: "/etc/modprobe.d/softdog.conf"
  become: true

# FIXME: install QemuServer hook to call this hook
